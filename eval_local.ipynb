{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "outputId": "caf05017-a1f4-4706-d281-63825edef5f5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "!pip install -q medmnist scikit-learn torchmetrics\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchmetrics.classification import MulticlassCalibrationError\n",
    "from medmnist import PathMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score, mean_absolute_error, brier_score_loss\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "from models import NCA, CNNBaseline\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "drive_folder = \"./data/\"\n",
    "cache_dir = os.path.expanduser(\"~/.medmnist\")\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "resolutions = [\"\", \"_64\", \"_128\", \"_224\"]\n",
    "for res in resolutions:\n",
    "    filename = f\"pathmnist{res}.npz\"\n",
    "    src = os.path.join(drive_folder, filename)\n",
    "    dst = os.path.join(cache_dir, filename)\n",
    "\n",
    "    if os.path.exists(src):\n",
    "        shutil.copyfile(src, dst)\n",
    "        print(f\"Copied {filename} to cache.\")\n",
    "    else:\n",
    "        print(f\"File not found in Drive: {filename}\")"
   ],
   "metadata": {
    "id": "349d3805c367abc6",
    "outputId": "c29fa00a-89e9-42ee-d069-b96521054faa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "is_executing": true
   },
   "id": "349d3805c367abc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nca = NCA().to(device)\n",
    "nca.load_state_dict(torch.load(\"./models/best_nca_pathmnist.pth\"))\n",
    "nca.eval()\n",
    "\n",
    "cnn = CNNBaseline().to(device)\n",
    "cnn.load_state_dict(torch.load(\"./models/best_cnn_pathmnist.pth\"))\n",
    "cnn.eval()"
   ],
   "metadata": {
    "id": "952872a274a32592",
    "outputId": "56b9688a-e4e3-4747-a87a-2c5a70762a89",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "is_executing": true
   },
   "id": "952872a274a32592"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_loader(size, batch_size=64):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = PathMNIST(split=\"test\", size=size, download=False, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "id": "fed7579ccabc28e4",
    "cellView": "code",
    "is_executing": true
   },
   "id": "fed7579ccabc28e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, name=\"Model\", size=28, save_dir=\"./results\", is_NCA=False):\n",
    "    all_preds, all_labels, all_logits = [], [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.squeeze()\n",
    "        if is_NCA:\n",
    "            out, rgb_steps = model(x, True)\n",
    "        else:\n",
    "            out = model(x)\n",
    "\n",
    "        all_logits.append(out.cpu())\n",
    "        pred = out.argmax(dim=1).cpu().numpy()\n",
    "        label = y.numpy()\n",
    "        all_preds.extend(pred)\n",
    "        all_labels.extend(label)\n",
    "\n",
    "    # Converting for scores\n",
    "    logits = torch.cat(all_logits)  # (N, C)\n",
    "    probs = F.softmax(logits, dim=1).numpy()  # (N, C)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Metrics\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    overall_acc = accuracy_score(all_labels, all_preds)\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "\n",
    "    ### Uncertainty Quantification (NQM)\n",
    "\n",
    "    # Brier Score\n",
    "    y_true_bin = label_binarize(all_labels, classes=list(range(probs.shape[1])))\n",
    "    brier = np.mean(np.sum((probs - y_true_bin) ** 2, axis=1))\n",
    "\n",
    "    # NLL (Cross-Entropy)\n",
    "    all_labels_tensor = torch.tensor(all_labels)\n",
    "    nll = F.cross_entropy(logits, all_labels_tensor, reduction='mean').item()\n",
    "\n",
    "    # Entroyp\n",
    "    entropy = -np.sum(probs * np.log(probs + 1e-12), axis=1)\n",
    "    mean_entropy = np.mean(entropy)\n",
    "\n",
    "    # ECE\n",
    "    probs_tensor = torch.from_numpy(probs).float()\n",
    "    labels_tensor = torch.from_numpy(all_labels).long()\n",
    "\n",
    "    ece_metric = MulticlassCalibrationError(num_classes=probs.shape[1], n_bins=15, norm='l1')\n",
    "    ece = ece_metric(probs_tensor, labels_tensor).item()\n",
    "\n",
    "    # Logging\n",
    "    print(f\"\\n{name} @ {size}x{size}\")\n",
    "    print(f\"Overall Accuracy: {overall_acc:.4f}\")\n",
    "    print(\"Balanced Accuracy:\", f\"{bal_acc:.4f}\")\n",
    "    print(\"Mean Absolute Error (MAE):\", f\"{mae:.4f}\")\n",
    "    print(\"\")\n",
    "    print(\"Uncertainty Quantification:\")\n",
    "    print(f\"Brier Score: {brier:.4f}\")\n",
    "    print(f\"NLL (Cross-Entropy)  : {nll:.4f}\")\n",
    "    print(f\"Mean Predictive Entropy: {mean_entropy:.4f}\")\n",
    "    print(f\"Expected Calibration Error (ECE): {ece:.4f}\")\n",
    "\n",
    "    print(report)\n",
    "\n",
    "    # Save confusion matrix\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix: {name} @ {size}x{size}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    fname = f\"{save_dir}/cm_{name.replace(' ', '_')}_{size}x{size}.png\"\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved to: {fname}\")\n",
    "\n",
    "    return {\n",
    "        \"overall_acc\": overall_acc,\n",
    "        \"bal_acc\": bal_acc,\n",
    "        \"mae\": mae,\n",
    "        \"brier\": brier,\n",
    "        \"nll\": nll,\n",
    "        \"entropy\": mean_entropy,\n",
    "        \"ece\": ece\n",
    "    }"
   ],
   "metadata": {
    "id": "cb4d8ed9ab50385b",
    "is_executing": true
   },
   "id": "cb4d8ed9ab50385b"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_comparison(results, save_dir=\"./results\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    metric_keys = [\"overall_acc\", \"bal_acc\", \"mae\", \"brier\", \"nll\", \"entropy\", \"ece\"]\n",
    "\n",
    "    for metric in metric_keys:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(results[\"CNN\"][\"size\"], results[\"CNN\"][metric], marker='o', label=\"CNN\")\n",
    "        plt.plot(results[\"NCA\"][\"size\"], results[\"NCA\"][metric], marker='s', label=\"NCA\")\n",
    "\n",
    "        plt.title(f\"{metric.replace('_', ' ').title()} vs Resolution\")\n",
    "        plt.xlabel(\"Image Size\")\n",
    "        plt.ylabel(metric.replace('_', ' ').title())\n",
    "        plt.xticks(results[\"CNN\"][\"size\"])  # saubere Ticks\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        fname = os.path.join(save_dir, f\"comparison_{metric}.png\")\n",
    "        plt.savefig(fname)\n",
    "        plt.close()\n",
    "        print(f\"Saved: {fname}\")"
   ],
   "metadata": {
    "id": "AwglZFGSuhSA",
    "is_executing": true
   },
   "id": "AwglZFGSuhSA",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"CNN\": {\"size\": [], \"overall_acc\": [], \"bal_acc\": [], \"mae\": [], \"brier\": [], \"nll\": [], \"entropy\": [], \"ece\": []},\n",
    "    \"NCA\": {\"size\": [], \"overall_acc\": [], \"bal_acc\": [], \"mae\": [], \"brier\": [], \"nll\": [], \"entropy\": [], \"ece\": []}\n",
    "}\n",
    "\n",
    "for size in [28, 64, 128, 224]:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Resolution: {size}x{size}\")\n",
    "    loader = get_loader(size)\n",
    "\n",
    "    print(\"CNN:\")\n",
    "    cnn_metrics = evaluate(cnn, loader, name=\"CNN\", size=size)\n",
    "    for k in cnn_metrics:\n",
    "        results[\"CNN\"][k].append(cnn_metrics[k])\n",
    "    results[\"CNN\"][\"size\"].append(size)\n",
    "\n",
    "    print(\"NCA:\")\n",
    "    nca_metrics = evaluate(nca, loader, name=\"NCA\", size=size, is_NCA=True)\n",
    "    for k in nca_metrics:\n",
    "        results[\"NCA\"][k].append(nca_metrics[k])\n",
    "    results[\"NCA\"][\"size\"].append(size)"
   ],
   "metadata": {
    "id": "cf3d183311fa590c",
    "outputId": "92f3ac24-5527-4625-9264-342142814d4d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "is_executing": true
   },
   "id": "cf3d183311fa590c"
  },
  {
   "cell_type": "code",
   "source": [
    "plot_comparison(results)"
   ],
   "metadata": {
    "id": "MvHBZn9YuSTN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "23ee9da4-f74d-4af6-e917-fc7d062d1cb4",
    "is_executing": true
   },
   "id": "MvHBZn9YuSTN",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
