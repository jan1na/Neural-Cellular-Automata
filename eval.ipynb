{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/jan1na/Neural-Cellular-Automata.git\n",
    "\n",
    "import os\n",
    "\n",
    "%cd Neural-Cellular-Automata"
   ],
   "metadata": {
    "id": "pGf1SgRGQHmM",
    "outputId": "63f08037-a3a1-49f4-f2f6-f30ab8ae4987",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "pGf1SgRGQHmM",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Neural-Cellular-Automata'...\n",
      "remote: Enumerating objects: 21, done.\u001B[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001B[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001B[K\n",
      "remote: Total 21 (delta 8), reused 12 (delta 5), pack-reused 0 (from 0)\u001B[K\n",
      "Receiving objects: 100% (21/21), 9.99 KiB | 9.99 MiB/s, done.\n",
      "Resolving deltas: 100% (8/8), done.\n",
      "/content/Neural-Cellular-Automata/Neural-Cellular-Automata/Neural-Cellular-Automata/Neural-Cellular-Automata\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "outputId": "e447f99c-ba21-4959-e2a1-cfc16d6b2ff8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "!pip install -q medmnist scikit-learn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from medmnist import PathMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, mean_absolute_error\n",
    "import seaborn as sns\n",
    "from models import NCA, CNNBaseline\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5efb41bd41839981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create MedMNIST cache directory\n",
    "cache_dir = os.path.expanduser(\"~/.medmnist\")\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# List of expected filenames\n",
    "files_needed = [\n",
    "    \"pathmnist.npz\",\n",
    "    \"pathmnist_64.npz\",\n",
    "    \"pathmnist_128.npz\",\n",
    "    \"pathmnist_224.npz\",\n",
    "]\n",
    "\n",
    "# Move uploaded files into the cache directory\n",
    "for fname in files_needed:\n",
    "    if fname in uploaded:\n",
    "        dest_path = os.path.join(cache_dir, fname)\n",
    "        if os.path.exists(dest_path):\n",
    "            os.remove(dest_path)  # Replace if already exists\n",
    "        shutil.move(fname, dest_path)\n",
    "        print(f\"{fname} moved to {dest_path}\")\n",
    "    else:\n",
    "        print(f\"File {fname} was not uploaded.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "349d3805c367abc6"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CNNBaseline(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "nca = NCA().to(device)\n",
    "nca.load_state_dict(torch.load(\"/content/drive/MyDrive/NCA/best_nca_pathmnist.pth\"))\n",
    "nca.eval()\n",
    "\n",
    "cnn = CNNBaseline().to(device)\n",
    "cnn.load_state_dict(torch.load(\"/content/drive/MyDrive/NCA/best_cnn_pathmnist.pth\"))\n",
    "cnn.eval()"
   ],
   "metadata": {
    "id": "952872a274a32592",
    "outputId": "38b098b1-281c-45e9-ad18-77605f68a6f2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "952872a274a32592"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_loader(size, batch_size=64):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = PathMNIST(split=\"test\", size=size, download=False, transform=transforms)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "id": "fed7579ccabc28e4"
   },
   "id": "fed7579ccabc28e4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, name=\"Model\", size=28, save_dir=\"/content/drive/MyDrive/NCA/results\"):\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.squeeze()\n",
    "        out = model(x)\n",
    "        pred = out.argmax(dim=1).cpu().numpy()\n",
    "        label = y.numpy()\n",
    "        all_preds.extend(pred)\n",
    "        all_labels.extend(label)\n",
    "\n",
    "    # Metrics\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "    # Logging\n",
    "    print(f\"\\n{name} @ {size}x{size}\")\n",
    "    print(\"Balanced Accuracy:\", f\"{bal_acc:.4f}\")\n",
    "    print(\"Mean Absolute Error (MAE):\", f\"{mae:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    # Save confusion matrix\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix: {name} @ {size}x{size}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    fname = f\"{save_dir}/cm_{name.replace(' ', '_')}_{size}x{size}.png\"\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved to: {fname}\")"
   ],
   "metadata": {
    "id": "cb4d8ed9ab50385b"
   },
   "id": "cb4d8ed9ab50385b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "==============================\n",
      "üñºÔ∏è  Resolution: 28x28\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 206M/206M [01:38<00:00, 2.08MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç CNN:\n",
      "\n",
      "CNN @ 28 Results\n",
      "[[1003    1    0    0   37    0    0    0    0]\n",
      " [  60  973    2    0   21    0    0    1    0]\n",
      " [   2    5  818   10    8   90   17  156   46]\n",
      " [   1    0    3 1121    1    0   12    5   13]\n",
      " [  10    4    2    1  768    2   44   46   13]\n",
      " [  30    2   86    1   14  985    5  225    6]\n",
      " [   3    0   11   11  108    5  628   36   75]\n",
      " [   0    1   94    2    7   91    3  822   25]\n",
      " [   3    1   53    7   21   13   61   83 1190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9020    0.9635    0.9317      1041\n",
      "           1     0.9858    0.9205    0.9521      1057\n",
      "           2     0.7652    0.7101    0.7366      1152\n",
      "           3     0.9722    0.9697    0.9710      1156\n",
      "           4     0.7797    0.8629    0.8192       890\n",
      "           5     0.8305    0.7275    0.7756      1354\n",
      "           6     0.8156    0.7161    0.7626       877\n",
      "           7     0.5983    0.7866    0.6796      1045\n",
      "           8     0.8699    0.8310    0.8500      1432\n",
      "\n",
      "    accuracy                         0.8305     10004\n",
      "   macro avg     0.8355    0.8320    0.8309     10004\n",
      "weighted avg     0.8388    0.8305    0.8319     10004\n",
      "\n",
      "üîÅ NCA:\n",
      "\n",
      "NCA @ 28 Results\n",
      "[[1017    7    0    0   15    1    1    0    0]\n",
      " [   0 1054    1    0    0    0    0    2    0]\n",
      " [   2    4  961    7    1   28    1  139    9]\n",
      " [   0    0    3 1141    0    0    4    3    5]\n",
      " [   1   19    3    0  820    0   26   17    4]\n",
      " [  12    2   25    0    2 1094    1  218    0]\n",
      " [   1    0    2   19   37    1  753    8   56]\n",
      " [   1    1   37    1    5   24    4  968    4]\n",
      " [   1    3   28    3   15    8   16   70 1288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9826    0.9769    0.9798      1041\n",
      "           1     0.9670    0.9972    0.9818      1057\n",
      "           2     0.9066    0.8342    0.8689      1152\n",
      "           3     0.9744    0.9870    0.9807      1156\n",
      "           4     0.9162    0.9213    0.9188       890\n",
      "           5     0.9464    0.8080    0.8717      1354\n",
      "           6     0.9342    0.8586    0.8948       877\n",
      "           7     0.6793    0.9263    0.7838      1045\n",
      "           8     0.9429    0.8994    0.9207      1432\n",
      "\n",
      "    accuracy                         0.9092     10004\n",
      "   macro avg     0.9166    0.9121    0.9112     10004\n",
      "weighted avg     0.9188    0.9092    0.9109     10004\n",
      "\n",
      "\n",
      "==============================\n",
      "üñºÔ∏è  Resolution: 64x64\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.07G/1.07G [05:12<00:00, 3.43MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç CNN:\n",
      "\n",
      "CNN @ 64 Results\n",
      "[[ 977   21    0    0   42    1    0    0    0]\n",
      " [  50  984    2    0   19    0    0    2    0]\n",
      " [   2    6  514    0   23  245   35  302   25]\n",
      " [   1    1  204  735   12    0  184   13    6]\n",
      " [   3    5    3    0  807    1   37   22   12]\n",
      " [  12    2   38    0   22 1096   11  173    0]\n",
      " [   0    1   12    0  420    0  344   13   87]\n",
      " [   0    0   30    0  109  188   21  671   26]\n",
      " [   1    2  133    0   33   12  198  207  846]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9340    0.9385    0.9363      1041\n",
      "           1     0.9628    0.9309    0.9466      1057\n",
      "           2     0.5491    0.4462    0.4923      1152\n",
      "           3     1.0000    0.6358    0.7774      1156\n",
      "           4     0.5427    0.9067    0.6790       890\n",
      "           5     0.7103    0.8095    0.7566      1354\n",
      "           6     0.4145    0.3922    0.4030       877\n",
      "           7     0.4783    0.6421    0.5482      1045\n",
      "           8     0.8443    0.5908    0.6952      1432\n",
      "\n",
      "    accuracy                         0.6971     10004\n",
      "   macro avg     0.7151    0.6992    0.6927     10004\n",
      "weighted avg     0.7293    0.6971    0.6989     10004\n",
      "\n",
      "üîÅ NCA:\n",
      "\n",
      "NCA @ 64 Results\n",
      "[[1006   20    0    0   13    0    2    0    0]\n",
      " [   0 1055    0    0    0    0    0    2    0]\n",
      " [   5    6  848    0   15   20    0  218   40]\n",
      " [   0    4    0  740   23    2   24   16  347]\n",
      " [   0   35    8    0  816    0   11    1   19]\n",
      " [   7   12  481    0   76  420    3  341   14]\n",
      " [   0    2    1    0  352    1  367    3  151]\n",
      " [   1    2  186    0  250   10   15  570   11]\n",
      " [   0    7   81    0   54    6   11  146 1127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9872    0.9664    0.9767      1041\n",
      "           1     0.9230    0.9981    0.9591      1057\n",
      "           2     0.5283    0.7361    0.6152      1152\n",
      "           3     1.0000    0.6401    0.7806      1156\n",
      "           4     0.5103    0.9169    0.6557       890\n",
      "           5     0.9150    0.3102    0.4633      1354\n",
      "           6     0.8476    0.4185    0.5603       877\n",
      "           7     0.4395    0.5455    0.4868      1045\n",
      "           8     0.6594    0.7870    0.7176      1432\n",
      "\n",
      "    accuracy                         0.6946     10004\n",
      "   macro avg     0.7567    0.7021    0.6906     10004\n",
      "weighted avg     0.7605    0.6946    0.6877     10004\n",
      "\n",
      "\n",
      "==============================\n",
      "üñºÔ∏è  Resolution: 128x128\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2.46G/4.26G [15:06<11:00, 2.72MB/s]   \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "\n                Automatic download failed! Please download pathmnist_128.npz manually.\n                1. [Optional] Check your network connection: \n                    Go to https://github.com/MedMNIST/MedMNIST/ and find the Zenodo repository\n                2. Download the npz file from the Zenodo repository or its Zenodo data link: \n                    https://zenodo.org/records/10519652/files/pathmnist_128.npz?download=1\n                3. [Optional] Verify the MD5: \n                    ac42d08fb904d92c244187169d1fd1d9\n                4. Put the npz file under your MedMNIST root folder: \n                    /root/.medmnist\n                ",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/medmnist/dataset.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m             download_url(\n\u001B[0m\u001B[1;32m    107\u001B[0m                 \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34mf\"url{self.size_flag}\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mcheck_integrity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmd5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"File not found or corrupted.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: File not found or corrupted.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-518664728>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"\\n==============================\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"üñºÔ∏è  Resolution: {size}x{size}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_loader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"üîç CNN:\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-1468036773>\u001B[0m in \u001B[0;36mget_loader\u001B[0;34m(size, batch_size)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_loader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mtransform\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCompose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mToTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPathMNIST\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"val\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mDataLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/medmnist/dataset.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, split, transform, target_transform, download, as_rgb, root, size, mmap_mode)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m         if not os.path.exists(\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/medmnist/dataset.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    111\u001B[0m             )\n\u001B[1;32m    112\u001B[0m         \u001B[0;32mexcept\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m             raise RuntimeError(\n\u001B[0m\u001B[1;32m    114\u001B[0m                 f\"\"\"\n\u001B[1;32m    115\u001B[0m                 \u001B[0mAutomatic\u001B[0m \u001B[0mdownload\u001B[0m \u001B[0mfailed\u001B[0m\u001B[0;31m!\u001B[0m \u001B[0mPlease\u001B[0m \u001B[0mdownload\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflag\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize_flag\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnpz\u001B[0m \u001B[0mmanually\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \n                Automatic download failed! Please download pathmnist_128.npz manually.\n                1. [Optional] Check your network connection: \n                    Go to https://github.com/MedMNIST/MedMNIST/ and find the Zenodo repository\n                2. Download the npz file from the Zenodo repository or its Zenodo data link: \n                    https://zenodo.org/records/10519652/files/pathmnist_128.npz?download=1\n                3. [Optional] Verify the MD5: \n                    ac42d08fb904d92c244187169d1fd1d9\n                4. Put the npz file under your MedMNIST root folder: \n                    /root/.medmnist\n                "
     ]
    }
   ],
   "source": [
    "for size in [28, 64, 128, 224]:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Resolution: {size}x{size}\")\n",
    "    loader = get_loader(size)\n",
    "\n",
    "    print(\"CNN:\")\n",
    "    evaluate(cnn, loader, name=\"CNN\", size=size)\n",
    "\n",
    "    print(\"NCA:\")\n",
    "    evaluate(nca, loader, name=\"NCA\", size=size)"
   ],
   "metadata": {
    "id": "cf3d183311fa590c",
    "outputId": "8729ff50-6078-4d61-8da5-acd6dd5f2995",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "id": "cf3d183311fa590c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
