{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jan1na/Neural-Cellular-Automata.git\n",
        "\n",
        "%cd Neural-Cellular-Automata"
      ],
      "metadata": {
        "id": "pGf1SgRGQHmM",
        "outputId": "1449d2c1-a365-4a41-f075-e57c20b045b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pGf1SgRGQHmM",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Neural-Cellular-Automata'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 74 (delta 43), reused 34 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (74/74), 146.66 KiB | 5.43 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "/content/Neural-Cellular-Automata/Neural-Cellular-Automata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown\n",
        "\n",
        "file_ids = ['1W7y-7ebqUCFW2ZPEsafABw_OPnXRr6cj',\n",
        "            '1L99QItxhTDj3dS1dd8ubmxka4FxXb2HG',\n",
        "            '1PqrOpn4NJF3xp4Jw2KtRRVD_20Feucsc',\n",
        "            '1DtZJ5eD2PV4sO51MMQy9CVTZxgBKj_Gx']\n",
        "\n",
        "file_names = ['pathmnist.npz', 'pathmnist_64.npz', 'pathmnist_128.npz', 'pathmnist_224.npz']\n",
        "\n",
        "for file_id, file_name in zip(file_ids, file_names):\n",
        "    !gdown --id {file_id} --output {file_name}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rpZOHk9G2SR",
        "outputId": "2310d63a-b7de-4457-bfa8-775e9bbd6903"
      },
      "id": "8rpZOHk9G2SR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/gdown\", line 4, in <module>\n",
            "    from gdown.__main__ import main\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gdown/__init__.py\", line 6, in <module>\n",
            "    from .cached_download import cached_download\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gdown/cached_download.py\", line 12, in <module>\n",
            "    from .download import download\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gdown/download.py\", line 13, in <module>\n",
            "    import bs4\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bs4/__init__.py\", line 64, in <module>\n",
            "    from .builder import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bs4/builder/__init__.py\", line 843, in <module>\n",
            "    from . import _lxml\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bs4/builder/_lxml.py\", line 29, in <module>\n",
            "    from lxml import etree\n",
            "  File \"<frozen importlib._bootstrap>\", line 405, in parent\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1L99QItxhTDj3dS1dd8ubmxka4FxXb2HG\n",
            "From (redirected): https://drive.google.com/uc?id=1L99QItxhTDj3dS1dd8ubmxka4FxXb2HG&confirm=t&uuid=fb3a44df-562d-480b-a558-a5640212acf5\n",
            "To: /content/Neural-Cellular-Automata/Neural-Cellular-Automata/pathmnist_64.npz\n",
            " 15% 161M/1.07G [00:00<00:04, 190MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rmkrrou1LBXf",
        "outputId": "850b49c1-220b-4925-99d1-a2dff30bd237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rmkrrou1LBXf",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "outputId": "e7a35414-3a4c-4a0d-c39c-2db1a6a4847c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install -q medmnist scikit-learn\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from medmnist import PathMNIST\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, mean_absolute_error\n",
        "import seaborn as sns\n",
        "from models import NCA, CNNBaseline\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-3530606824.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Copied {filename} to cache.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0m_USE_CP_SENDFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36m_fastcopy_sendfile\u001b[0;34m(fsrc, fdst)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# ...in oder to have a more informative exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "drive_folder = \"/content/Neural-Cellular-Automata/\"\n",
        "cache_dir = os.path.expanduser(\"~/.medmnist\")\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "resolutions = [\"\", \"_64\", \"_128\", \"_224\"]\n",
        "for res in resolutions:\n",
        "    filename = f\"pathmnist{res}.npz\"\n",
        "    src = os.path.join(drive_folder, filename)\n",
        "    dst = os.path.join(cache_dir, filename)\n",
        "\n",
        "    if os.path.exists(src):\n",
        "        shutil.copyfile(src, dst)\n",
        "        print(f\"Copied {filename} to cache.\")\n",
        "    else:\n",
        "        print(f\"File not found in Drive: {filename}\")"
      ],
      "metadata": {
        "id": "349d3805c367abc6",
        "outputId": "d97abc64-148a-4181-e410-60fdd0a70e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "id": "349d3805c367abc6"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNBaseline(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "  )\n",
              "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=128, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "nca = NCA().to(device)\n",
        "nca.load_state_dict(torch.load(\"/content/drive/MyDrive/NCA/best_nca_pathmnist.pth\"))\n",
        "nca.eval()\n",
        "\n",
        "cnn = CNNBaseline().to(device)\n",
        "cnn.load_state_dict(torch.load(\"/content/drive/MyDrive/NCA/best_cnn_pathmnist.pth\"))\n",
        "cnn.eval()"
      ],
      "metadata": {
        "id": "952872a274a32592",
        "outputId": "50f0c11b-0047-49c2-9c55-166200335b8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "952872a274a32592"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "def get_loader(size, batch_size=64):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    dataset = PathMNIST(split=\"test\", size=size, download=False, transform=transform)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "fed7579ccabc28e4",
        "cellView": "code"
      },
      "id": "fed7579ccabc28e4"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, loader, name=\"Model\", size=28, save_dir=\"/content/drive/MyDrive/NCA/results\", is_NCA=False):\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.squeeze()\n",
        "        if is_NCA:\n",
        "            out, rgb_steps = model(x, True)\n",
        "        else:\n",
        "            out = model(x)\n",
        "        pred = out.argmax(dim=1).cpu().numpy()\n",
        "        label = y.numpy()\n",
        "        all_preds.extend(pred)\n",
        "        all_labels.extend(label)\n",
        "\n",
        "    # Metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, digits=4)\n",
        "\n",
        "    # Logging\n",
        "    print(f\"\\n{name} @ {size}x{size}\")\n",
        "    print(\"Balanced Accuracy:\", f\"{bal_acc:.4f}\")\n",
        "    print(\"Mean Absolute Error (MAE):\", f\"{mae:.4f}\")\n",
        "    print(report)\n",
        "\n",
        "    # Save confusion matrix\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Confusion Matrix: {name} @ {size}x{size}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    fname = f\"{save_dir}/cm_{name.replace(' ', '_')}_{size}x{size}.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "    print(f\"Confusion matrix saved to: {fname}\")"
      ],
      "metadata": {
        "id": "cb4d8ed9ab50385b"
      },
      "id": "cb4d8ed9ab50385b"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "Resolution: 28x28\n",
            "CNN:\n",
            "\n",
            "CNN @ 28x28\n",
            "Balanced Accuracy: 0.4015\n",
            "Mean Absolute Error (MAE): 1.9591\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.0919    0.1684      1338\n",
            "           1     0.8777    1.0000    0.9349       847\n",
            "           2     0.3106    0.7375    0.4371       339\n",
            "           3     0.0000    0.0000    0.0000       634\n",
            "           4     0.3677    0.9894    0.5361      1035\n",
            "           5     0.6000    0.0963    0.1659       592\n",
            "           6     0.3621    0.1134    0.1727       741\n",
            "           7     0.0851    0.0095    0.0171       421\n",
            "           8     0.3347    0.5758    0.4234      1233\n",
            "\n",
            "    accuracy                         0.4316      7180\n",
            "   macro avg     0.4375    0.4015    0.3173      7180\n",
            "weighted avg     0.5069    0.4316    0.3448      7180\n",
            "\n",
            "Confusion matrix saved to: /content/drive/MyDrive/NCA/results/cm_CNN_28x28.png\n",
            "NCA:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NCA @ 28x28\n",
            "Balanced Accuracy: 0.2798\n",
            "Mean Absolute Error (MAE): 1.8765\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000      1338\n",
            "           1     0.3238    0.9988    0.4890       847\n",
            "           2     0.8778    0.4661    0.6089       339\n",
            "           3     0.0000    0.0000    0.0000       634\n",
            "           4     0.5315    0.1710    0.2588      1035\n",
            "           5     0.2188    0.0236    0.0427       592\n",
            "           6     0.0016    0.0013    0.0015       741\n",
            "           7     0.1682    0.6105    0.2637       421\n",
            "           8     0.1655    0.2466    0.1980      1233\n",
            "\n",
            "    accuracy                         0.2447      7180\n",
            "   macro avg     0.2541    0.2798    0.2070      7180\n",
            "weighted avg     0.2127    0.2447    0.1769      7180\n",
            "\n",
            "Confusion matrix saved to: /content/drive/MyDrive/NCA/results/cm_NCA_28x28.png\n",
            "\n",
            "==============================\n",
            "Resolution: 64x64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset not found.  You can set `download=True` to download it",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-319744685.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n==============================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Resolution: {size}x{size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-14-507979941.py\u001b[0m in \u001b[0;36mget_loader\u001b[0;34m(size, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPathMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/medmnist/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, split, transform, target_transform, download, as_rgb, root, size, mmap_mode)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.flag}{self.size_flag}.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         ):\n\u001b[0;32m---> 61\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;34m\"Dataset not found. \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" You can set `download=True` to download it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found.  You can set `download=True` to download it"
          ]
        }
      ],
      "source": [
        "for size in [28, 64, 128, 224]:\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"Resolution: {size}x{size}\")\n",
        "    loader = get_loader(size)\n",
        "\n",
        "    print(\"CNN:\")\n",
        "    evaluate(cnn, loader, name=\"CNN\", size=size)\n",
        "\n",
        "    print(\"NCA:\")\n",
        "    evaluate(nca, loader, name=\"NCA\", size=size, is_NCA=True)"
      ],
      "metadata": {
        "id": "cf3d183311fa590c",
        "outputId": "7119fc9c-5ec5-4fb1-b4fa-582aae80045b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "cf3d183311fa590c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}